\section{Teoria dei Grafi}
La teoria dei grafi è una branca della matematica, nata nel 1700 con Eulero, che consente di descrivere le relazioni che intercorrono tra un insieme di oggetti.\\
Il grafo è lo strumento attraverso il quale tali relazioni possono essere espresse ed organizzate. Infatti, il grafo, consiste di oggetti chiamati \textit{nodi} e relazioni tra coppie di questi oggetti detti \textit{archi}; nodi connessi tra loro da un arco sono detti \textit{vicini} o \textit{adiacenti}.\\

\begin{figure}[h!]
	\centering
	\includegraphics[scale=.5]{img/Wikipedia_multilingual_network_graph_July_2013.png}
	\caption{Wikipedia Multilingual Network Graph (July 2013)}
\end{figure}
\newpage
La relazione tra una coppia di nodi può essere di due tipi:
\begin{itemize}
	\item Simmetrica: l'arco connette i nodi con un collegamento bidirezionale ed è detto \textit{indiretto}. Un grafo costituito di soli archi indiretti è anch'esso detto indiretto.
	\item Asimmetrica: l'arco connette i nodi con un collegamento unidirezionale ed è detto \textit{diretto}. Un grafo costituito di soli archi diretti è anch'esso detto diretto.
\end{itemize}
\begin{figure}[h!]
	\vspace*{1cm}
	\begin{minipage}{0.45\textwidth}
	\centering
	\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=2cm,
		thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]
		\node[main node] (1) {1};
		\node[main node] (2) [below left of=1] {2};
		\node[main node] (3) [below right of=2] {3};
		\node[main node] (4) [below right of=1] {4};
		\path[every node/.style={font=\sffamily\small}]
		(1) edge node [left] {} (4)
		
		(2) edge node [right] {} (1)
		
		(3) edge node [right] {} (2)
		
		(4) edge node [left] {} (3);
		
	\end{tikzpicture}
	\caption{Grafo indiretto}
	\end{minipage}\hfill
% <-- needed to keep the imgs side by side
	\begin{minipage}{0.45\textwidth}
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
		thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]
		\node[main node] (1) {1};
		\node[main node] (2) [below left of=1] {2};
		\node[main node] (3) [below right of=2] {3};
		\node[main node] (4) [below right of=1] {4};
		\path[every node/.style={font=\sffamily\small}]
		(1) edge node [left] {} (4)
		
		(2) edge node [right] {} (1)
		
		(3) edge node [right] {} (2)
		
		(4) edge node [left] {} (3);
	\end{tikzpicture}
	\caption{Grafo diretto}
	\end{minipage}
\end{figure}
Un grafo può essere formalmente descritto come una coppia di insiemi \textbf{G = (V, E)}, dove V è l'insieme dei nodi ed E è l'insieme degli archi. Un arco e $\in$ E è rappresentato come un sottoinsieme di due elementi di V, $e = \lbrace u, v\rbrace$ per $u, v \in V$.\\
Le rappresentazioni atte a descrivere un grafo sono molteplici:
\begin{itemize}
	\item \textit{Rappresentazione grafica}: ad ogni nodo corrisponde una figura circolare sul piano e ad ogni arco (i, j) corrisponde una linea che che collega il nodo i al nodo j.
	\item \textit{Matrice di adiacenza}: matrice di dimensione $n \times n$, dove $n$ è il numero di nodi, il cui elemento (i, j) assume valore 1 se esiste l'arco tra il nodo i ed il nodo j, 0 altrimenti.
	\item \textit{Lista di adiacenza}: ad ogni vertice $v$ è associata la lista dei nodi ad esso vicini.
\end{itemize}
Negli anni, gli studi sulla teoria dei grafi hanno prodotto una quantità enorme di definizioni e teoremi, per cui, di seguito vengono descritti solamente i concetti necessari alla comprensione di questo lavoro di tesi.
\paragraph{Sottografo.} Un grafo H si dice sottografo di un grafo G se i vertici di H sono un sottoinsieme dei vertici di G e gli archi di H sono un sottoinsieme degli archi di G. Siano $G=(V, E)$ ed $H=(V_1, E_1)$ due grafi. H è un sottografo di G se e solo se $V_1 \subseteq V$ ed $E_1 \subseteq E$.
Un concetto particolarmente utile alla comprensione di questo lavoro è lo \textit{spanning subgraph}: uno spanning subgraph H di un grafo G è un sottografo che contiene tutti i vertici di G, cioé $V_1 = V$.
\paragraph{Grado di un nodo.} Il grado di un nodo $v$ è il numero di nodi ad esso adiacenti ed è indicato con \textit{deg(v)}.\\
In un grafo diretto, si distinguono due tipi di grado:
\begin{itemize}
	\item \textit{in-deg(v)}, il grado in ingresso del nodo \textit{v}, dato dal numero di archi in cui \textit{v} compare come nodo destinazione;
	\item \textit{out-deg(v)}, il grado in uscita del nodo \textit{v}, dato dal numero di archi in cui \textit{v} compare come nodo sorgente.
\end{itemize}
\paragraph{Cammino.} Un cammino è una sequenza di nodi, in cui ogni coppia consecutiva della sequenza sia connessa da un arco. Formalmente, un cammino è una sequenza di vertici $v_0, v_1, \cdots, v_n \in V$ tale che $\lbrace v_{i-1}, v_i\rbrace \in E, \forall 1\leq i \leq n$. Un cammino con almeno tre vertici distinti, i cui vertici di inizio e fine coincidono, è detto \textit{ciclo}.
\paragraph{Grafo connesso.} Un grafo è connesso se, per ogni coppia distinta di vertici (i, j), esiste un cammino da i a j.

\subsection{Grafo come modello della realtà}
I grafi hanno una grande utilità, in quanto consentono di astrarre le relazioni che intercorrono tra più oggetti, e di rappresentare tali relazioni in strutture su cui è possibile applicare modelli matematici. In \cite{easley2010networks} viene proposto un esempio reale: la Figura \ref{arpanet} rappresenta la struttura della rete Internet nel Dicembre del 1970, noto come ARPANET allora, composto solo da 13 macchine. I nodi rappresentano gli host, e vi è un arco tra due host se esiste una comunicazione diretta tra di essi.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=.7]{img/arpanetdec1970.jpg}
	\caption{ARPANET nel Dicembre 1970}
	\label{arpanet}
\end{figure}
Come è possibile intuire, la posizione geografica dei nodi non ha molta importanza, ma quel che conta è il come ogni nodo sia connesso agli altri. Infatti la figura \ref{arpanet_graph} mostra lo stesso grafo di ARPANET, attraverso una rappresentazione logica.
\begin{figure}
	\centering
	\includegraphics[scale=.5]{img/arpanetdec1970_graph.png}
	\caption{Grafo di ARPANET nel Dicembre 1970}
	\label{arpanet_graph}
\end{figure}
Il grafo di ARPANET mostrato in precedenza è un esempio di \textit{\textbf{communication network}}, i cui nodi sono computer o altri dispositivi capaci di inviare messaggi mentre gli archi rappresentano i collegamenti diretti lungo i quali tali messaggi possono viaggiare. Ma questo è solamente uno dei tipi di rete che possiamo avere.\\
Le \textit{\textbf{social network}} i cui nodi sono persone o gruppi di persone, ed i cui archi rappresentano un tipo di interazione (amicizia, inimicizia, ecc.), sono reti massive che al giorno d'oggi comprendono gran parte della popolazione mondiale, come ad esempio le reti di Facebook e Twitter.\\
Le \textit{\textbf{information network}} sono reti che rappresentano il mondo dell'informazione, i cui nodi sono le fonti di informazione e gli archi rappresentano collegamenti logici come riferimenti, citazioni identificati da hyperlink. A tale categoria appartiene il grafo del Web, così come la rete di documenti di Wikipedia.\\
Le \textit{\textbf{dependency network}}, che descrivono le dipendenze esistenti in una collezione di oggetti. Ne sono esempi reti di dipendenze tra task, per cui sono stati sviluppati molti lavori, applicati anche in altri campi come lo studio del sistema immunitario e delle reti semantiche.\\
I grafi mostrano la loro grande utilità anche nelle \textit{\textbf{transportation network}}, reti i cui nodi sono luoghi geografici ed i cui archi sono le linee stradali, ferroviarie o aeree che li collegano. Questo tipo di rete è stata di grande importanza nello sviluppo di concetti ed algoritmi su grafi, infatti molta della terminologia deriva dal mondo dei trasporti.\\
Quindi, come si evince dai vari tipi di network descritte finora, i grafi sono uno strumento potente che trova applicazione nelle realtà più disparate, partendo dalla matematica ed informatica, fino ad arrivare agli studi della sociologia, biologia, linguistica, chimica e fisica. Ed è proprio l'ultimo ambito ad interessare questo lavoro di tesi: la \textit{fisica statistica} è una branca della fisica che utilizza metodi della teoria delle probabilità e statistici, ed in particolare gli strumenti matematici usati per gestire grandi popolazioni ed approssimazioni, per la risoluzione di problemi fisici. Può descrivere una grande varietà di campi dotati di una natura stocastica intrinseca. Le sue applicazioni coinvolgono problemi nel campo della fisica, biologia, chimica, neurologia e scienze sociali.\\
Lo scopo finale per cui nasce la fisica statistica, in particolare la meccanica statistica, è quello di fornire strutture e strumenti per mettere in relazione proprietà microscopiche di atomi e molecole individuali rispetto a proprietà del materiale che possono essere osservate ad occhio nudo. Spiegando ad esempio la termodinamica come il risultato naturale di statistica, meccanica classica e meccanica quantistica al livello microscopico: il grafo riesce a modellare le particelle del sistema su cui agisce la dinamica del processo fisico.


\section{Modello di Ising}
Il modello di Ising è un classico problema combinatoriale della fisica statistica, studiato per la prima volta da Ernest Ising nel 1920. Tale modello è interessato alla fisica delle transizioni di fase, che occorrono quando un piccolo cambiamento nei parametri, come temperatura o pressione, causa un grande cambiamento qualitativo nello stato del sistema. Le transizioni di fase sono comuni nella fisica, come ad esempio nel fenomeno del ferromagnetismo.\\
Uno degli scopi principali del modello di Ising è spiegare come interazioni di breve raggio tra le componenti del sistema siano in grado di dare luogo a comportamenti correlati di lungo raggio e, quindi, di predire in un certo senso il potenziale per una transizione di fase. Tale modello trova applicazione in molti ambiti, in generale in tutti quegli ambiti dove si studia il comportamento cooperativo di grandi sistemi: tali applicazioni sono possibili perché il modello di Ising può essere formulato come un problema matematico.\\
Una semplice definizione matematica del modello di Ising è data in \cite{cipra1987introduction} e in \cite{jerrum1993polynomial}: consideriamo una collezione di siti $\lbrack n \rbrack = \lbrace 0, 1, \cdots, n-1 \rbrace$, in cui ogni coppia $i, j$ ha associata un’energia di interazione $V_{ij}$. Nella maggior parte dei casi di interesse fisico, l’insieme E di coppie con energia di interazione non nulla forma un \textit{regular lattice graph} $([n], E)$: detto anche \textit{mesh graph} o \textit{grid graph}, è un grafo la cui rappresentazione grafica sul piano forma delle tassellature regolari.\\
Il primo passo del modello è quello di assegnare ad ogni sito \textit{i} una variabile $\sigma_i$, detta \textbf{spin}, con $i=1, \dots, n$. Le variabili $\sigma_i$ possono assumere solo due valori, $\sigma_i = \pm 1$, che si possono definire come gli \textit{stati} dei siti.\\
Una \textbf{configurazione} $\sigma$ del sistema è un assegnamento di spin positivi $\left( \sigma_i = 1 \right)$ o negativi $\left( \sigma_i = 1 \right)$ ad ogni sito $i \in \lbrack n \rbrack$.\\
L'\textit{energia} di una configurazione è data dall’Hamiltoniana del sistema: nella fisica matematica, tale quantità governa le dinamiche del sistema. Per il modello di Ising, l’Hamiltoniana è definita sotto un’assunzione ben precisa: si assume che solo le interazioni di breve raggio e con i siti più vicini e le interazioni dei siti con un ``campo esterno'' contribuiscono al livello di energia del sistema. Pertanto, per ogni configurazione $\sigma = (\sigma_1, \dots, \sigma_n)$ si ha:\\
\begin{equation}
H(\sigma) = - \sum_{\lbrace i,j \rbrace \in E}{V_{ij}\sigma_i\sigma_j} - B \sum_{k\in\lbrack n \rbrack}{\sigma_k}
\end{equation}
in cui la prima sommatoria varia su tutte le coppie di vicini nel lattice graph mentre la seconda varia su tutti i siti del sistema. $V_{ij}$ e B sono parametri associati rispettivamente alle interazioni dei vicini ed alle interazioni con il campo esterno.\\
Nel caso in cui tutte le energie di interazione siano non negative, tale sistema modella il comportamento di un \textit{ferromagnete}: una configurazione ``'magnetizzata' (con la maggior parte di coppie di siti vicini aventi $\sigma_i = \sigma_j$), ha un livello di energia più basso rispetto ad una configurazione non magnetizzata. Il parametro B corrisponde alla presenza di un ``campo magnetico esterno''.
\subsection{Partition Function}
La funzione di partizione è senza alcun dubbio l'oggetto di maggior rilievo introdotto dalla meccanica statistica. La si ottiene dall'esponenziazione dell'Hamiltoniana e sommando su tutte le possibili configurazioni $\sigma$, cioè su $2^n$ possibili assegnamenti di valori $\pm1$ alle $n$ variabili $(\sigma_1, \dots, \sigma_n)$:
\begin{equation}
	Z = Z(V_{ij}, B, \beta) = \sum_{\sigma}{exp(-\beta H(\sigma))}.
\end{equation}
Nell'ambito della meccanica statistica, solitamente $\beta = 1 / kT$, dove $k$ è la costante di Boltzmann e T è la temperatura $(\beta > 0)$.\\
La partition function è utilizzata come ``denominatore'' nel calcolo delle probabilità. In particolare, la probabilità che il sistema si trovi in una specifica configurazione $\sigma$ è data dalla formula
\begin{equation}
	P(\sigma) = \frac{e^{-\beta H(\sigma)}}{Z}
\end{equation}
Il segno negativo apporta una maggiore probabilità agli stati con energia più bassa. Valori bassi di $\beta$, corrispondenti ad alta temperatura, tendono ad ``appiattire'' la distribuzione, rendendo così tutte le configurazioni equiprobabili o quasi. Alti valori di $\beta$, corrispondenti a bassa temperatura, tendono ad apportare maggiore probabilità agli stati con energia minore.\\
È possibile ottenere, a partire dalla partition function Z, due quantità altrettanto importanti, la \textit{mean energy} $\epsilon = -\partial(ln Z)/\partial\beta$ ed il \textit{mean magnetic moment} $\mathcal{M} = \beta^{-1}\partial(ln Z)/\partial\beta$.
\section{Cenni di probabilità e statistica}
Di seguito vengono riportati concetti e definizioni utili alla comprensione di questo lavoro di tesi (per maggiori dettagli consultare \cite{grinstead2012introduction}).\\
\paragraph{Spazio delle probabilità.} Tripla $(\Omega, F, P)$, dove $\Omega$ è lo \textit{spazio campionario}, cioè l'insieme dei possibili esiti (o \textit{outcome}), $F$ è l'insieme degli eventi, mentre $P : \mathcal{F} \rightarrow [0, 1]$ è una funzione che assegna probabilità ad eventi.\\
\paragraph{Variabile aleatoria.} Definita su uno spazio di probabilità, esprime il valore numerico di un outcome di un evento. Una variabile aleatoria \textit{X} è una funzione definita sullo spazio degli outcome $\Omega$, ed associa ad ogni elemento di $\Omega$ un valore in $\mathcal{R}$.
Sia \textit{X} una variabile casuale che rappresenta il valore degli outcome di un certo evento e si assuma che tale evento possa avere solo un numero finito di possibili outcome. Sia $\Omega$ lo spazio campionario dell'esperimento. Una \textit{funzione di distribuzione} per \textit{X} è una funzione \textit{p} di valori reali il cui dominio è $\Omega$ e che soddisfa $p(\omega) \geq 0$ e $\sum{p(\omega)} = 1$, con $\omega \in \Omega$.\\
Per ogni sottoinsieme \textit{E} di $\Omega$, definiamo la \textit{probabilità} di \textit{E} come
\begin{equation}
	P(E) = \sum_{\omega \in E}{p(\omega)}.
\end{equation}
La funzione $p(\omega)$ è la \textbf{distribuzione di probabilità} della variabile aleatoria \textit{X}.
\paragraph{Valore atteso.} Sia \textit{X} una variabile casuale discreta con spazio campionario $\Omega$ e funzione di distribuzione $p(x)$. Il \textit{valore atteso E(X)} è definito come
\begin{equation}
	E(X) = \sum_{x\in \Omega} x p(x)
\end{equation}
a patto che tale sommatoria converga (altrimenti X non avrebbe valore atteso).
Di solito, il valore atteso è anche chiamato \textit{media}, ed è indicato con il simbolo $\mu$. Alcune delle principali proprietà di cui gode il valore atteso sono riportate di seguito:
\begin{itemize}
	\item Siano $X$ ed $Y$ due variabili aleatorie con valori attesi finiti, allora $E(X+Y) = E(X) + E(Y)$
	\item Sia X una variabile aleatoria con valore atteso finito e sia $c$ una costante, allora $E(cX) = cE(X)$
	\item Siano X e Y due variabili aleatorie indipendenti, allora $E(X\cdot Y) = E(X) \dot E(Y)$.
\end{itemize}
\paragraph{Varianza.} Sia \textit{X} una variabile casuale con valore atteso $\mu = E(X)$. Allora la \textit{varianza} di X, indicata con $V(X)$, o con $\sigma^2$, è pari a
\begin{equation}
	V(X) = E((X - \mu^2)).
\end{equation}
La varianza può essere anche scritta come
\begin{equation}
	V(X) = \sum_x {(x - \mu^2)p(x)}.
\end{equation}
Una utile alternativa al calcolo della varianza è data dal seguente teorema: \textit{sia X una variabile casuale con} $E(X) = \mu^2$, \textit{allora} $V(X) = E(X^2) - \mu^2$. Per maggiori dettagli riguardati la prova di tale teorema, consultare pagina 258 di \cite{grinstead2012introduction}.\\
Alcune importanti proprietà della varianza:
\begin{itemize}
	\item Sia \textit{X} una variabile casuale e $c$ una costante, allora $V(cX) = c^2V(X)$
	\item Siano $X$ ed $Y$ due variabili casuali indipendenti, allora $V(X+Y) = V(X) + V(Y)$.
\end{itemize}
\paragraph{Disuguaglianza di Chebyshev.} Sia \textit{X} una variabile casuale con valore atteso finito $\mu$ e varianza non negativa finita $\sigma^2$. Allora per qualsiasi numeri reale $k > 0$ si ha che
\begin{equation}
	Pr(|X - \mu| \geq k) \leq \frac{\sigma^2}{k^2}.
\end{equation}
Tale disuguaglianza garantisce che in qualsiasi distribuzione di probabilità, quasi tutti i valori siano vicini alla media.
\section{Processi Markoviani}\label{sec:markovproc}
Di seguito sono introdotti i concetti alla base delle catene di Markov (consultare \cite{levin2009markov} per maggiori dettagli).\\
Una catena di Markov finita è un processo che si muove tra gli elementi di un insieme finito $\Omega$ nel seguente modo: se si suppone di trovarsi in $x \in \Omega$, allora la prossima posizione è scelta in accordo ad una distribuzione di probabilità fissata $P(x, \cdot)$. Più precisamente, una sequenza di variabili casuali $(X_0, X_1, \dots)$ è una \textbf{catena di Markov con spazio degli stati $\Omega$ e matrice di transizione P} se per tuttu gli $x,y \in \Omega$, per tutti i $t \geq 1$, e per tutti gli eventi $H_{t-1} = \bigcap_{s=0}^{t-1}{X_s = x_s}$ che soddisfano $Pr(H_{t-1} \cap {X_t = x}) > 0$, si ha
\begin{equation}
	Pr(X_{t+1} = y | H_{t-1} \cap {X_t = x}) = Pr(X_{t+1} = y | X_t = x) = Pr(x, y).
	\label{pr_xy}
\end{equation}
L'equazione \ref{pr_xy}, nota come \textit{proprietà di Markov}, sta a significare che la probabilità condizionale di procedere dallo stato $x$ allo stato $y$ è la stessa, non importa quale sia la lunghezza degli stati $x_0, \dots, x_{t-1}$ che precedono lo stato corrente $x$. 
\subsection{Irriducibilità e periodicità}
Una catena di Markov P è detta \textbf{irriducibile} se, per qualsiasi coppia di stati $x, y \in \Omega$, esiste un intero \textit{t} tale che $P^t(x, y) > 0$. L'affermazione sta ad indicare che è possibile andare da uno stato in un qualsiasi altro stato utilizzando solo transizioni di probabilità positive.\\
Sia $\mathcal{T}(x) := {t \geq 1 : P^{t}(x,x) > 0}$ l'insieme di volte in cui è possibile per la catena ritornare nella posizione iniziale $x$. Il \textbf{periodo} di $x$ è definito come il \textit{massimo comune divisore (gcd)} di $\mathcal{T}(x)$.\\
\paragraph{Lemma.} \textit{Se P è irriducibile, allora gcd($\mathcal{T}(x)$) = gcd($\mathcal{T}(y)$)} $\forall x, y \in \Omega$.\\
Data una catena irriducibile, il periodo della catena è definito come il periodo che è comune a tutti gli stati. La catena sarà detta \textit{aperiodica} se tutti gli stati hanno periodo 1, altrimenti \textit{periodica}.
\paragraph{Proposizione.} \textit{Se P è aperiodica ed irriducibile, allora vi è un intero r t.c.} $P^r(x, y) > 0 \forall x, y \in \Omega$.\\
Una catena di Markov finita (con spazio degli stati $\Omega$ finito), \textit{irriducibile} ed \textit{aperiodica} è detta \textbf{ergodica}.
\subsection{Distribuzione stazionaria}
Sia $\pi$ una distribuzione di probabilità. Se tale distribuzione soddisfa
\begin{equation}
	\pi = \pi P
\end{equation}
allora $\pi$ è detta \textit{distribuzione stazionaria} della catena di Markov. tale distribuzione può essere riscritta anche per i singoli elementi della catena:
\begin{equation}
	\pi(x) = \sum_{x\in \Omega}{\pi(x)P(x, y)} \forall x,y \in \Omega.
\end{equation}
Il risultato ben noto, che si ottiene dalla teoria dei processi Markoviani è che se la catena in questione è ergodica, allora la distribuzione stazionaria è \textit{unica}.\\
Una catena di Markov è detta \textit{reversibile} se
\begin{equation}
	\pi(x)P(x,y) = \pi(y)P(y,x) \forall x,y \in \Omega.
	\label{revchain}
\end{equation}
Quindi, data una catena $(X_t)$ che soddisfa \ref{revchain} ed ha una distribuzione stazionaria iniziale, allora la distribuzione di $(X_0, X_1, \dots, X_n)$ è la stessa di $(X_n, X_{n-1}, \dots, X_0)$.\\
Un risultato di grande importanza è il \textit{teorema della convergenza}: tale teorema prova che una catena di Markov irriducibile ed aperiodica converge alla sua distribuzione stazionaria.\\
Prima di enunciare il problema, però, è necessaria la definizione di \textit{total variation distance}: siano $\pi$ e $\mu$ due distribuzioni di probabilità sullo stesso spazio campionario $\Omega$, allora la total variation distance è definita come
\begin{equation}
	\|\pi - \mu\| = max_{A\subset\Omega}|\pi(A) - \mu(A)| = \frac{1}{2}\sum_{x\in\Omega}{|\pi(x) - \mu(x)|}.
\end{equation}
Si enuncia ora, il \textbf{teorema della convergenza}:
\paragraph{Teorema.} \textit{Si supponga che P sia irriducibile ed aperiodica, con distribuzione stazionaria $\pi$. Allora esistono due costanti $\alpha \in (0,1) e C > 0 t.c.$}
\begin{equation}
	max_{x\in\Omega}\|P^t(x,\cdot) - \pi\| \leq C\alpha^t.
	\label{convth}
\end{equation}
Per la dimostrazione e maggiori dettagli consultare \cite{levin2009markov} (pag. 52).
\subsection{Catena di Markov Monte Carlo}
Data una matrice di transizione irriducibile \textit{P}, vi è un'unica distribuzione stazionaria $\pi$ che soddisfa $\pi = \pi P$, come affermato nella sezione precedente.\\
Si consideri ora il problema inverso: data una distribuzione di probabilità $\pi$ su $\Omega$, è possibile trovare una matrice di transizione \textit{P} per cui $\pi$ è la distribuzione stazionaria? \cite{levin2009markov} fornisce un esempio pratico per capire come risolvere tale problema.\\
Il \textit{campione casuale} da un insieme finito $\Omega$ è definito come una selezione uniformemente casuale da $\Omega$; una selezione tale che ogni elemento ha la stessa probabilità $1/|\Omega|$ di essere scelto.\\
Sia ${1, 2, \dots, q}$ un insieme di \textit{colori}. Un \textit{proper q-coloring} di un grafo $G=(V, E)$ è un assegnamento di colori ai vertici di V, con il vincolo che nodi vicini non debbano avere lo stesso colore. Per alcune tipologie di grafo, come ad esempio gli alberi, esistono semplici metodi ricorsivi che generano una colorazione casuale; per altri grafi, invece, risulta più difficile. un approccio consiste nell'utilizzare le catene di Markov per campionare: supponiamo che $(X_t)$ sia una catena con spazio degli stati $\Omega$ e con una distribuzione stazionaria uniforme su $\Omega$. Grazie al teorema della convergenza enunciato in \ref{convth}, $X_t$ è approssimativamente uniformemente distribuita quando $t$ è grande.\\
tale metodo di campionamento a partire da una data distribuzione di probabilità è chiamato \textit{\textbf{Catena di Markov Monte Carlo}}. Si supponga che $\pi$ sia una distribuzione di probabilità su $\Omega$. se + possibile costruire una catena di Markov $(X_t)$ con distribuzione stazionaria $\pi$ allora, per $t$ grande abbastanza si ha che la distribuzione di $X_t$ è vicina a $\pi$.
\section{Algoritmi di approssimazione}\label{sec:approxalgo}
Un \textit{\textbf{$\alpha$-approximation algorithm}} per un dato problema è un algoritmo con tempo di esecuzione polinomiale che, per tutte le istanze del problema, produce una soluzione il cui valore è entro un fattore $\alpha$ del valore della soluzione ottima.\\
Dato un $\alpha$-approximation algorithm, $\alpha$ è la \textit{performance} garantita dell'algoritmo. In letteratura è spesso anche chiamato \textit{rapporto di approssimazione} o \textit{fattore di approssimazione}.\\
Un \textit{\textbf{polynomial time approximation scheme}} è una famiglia di algoritmi ${A_\epsilon}$, in cui vi è un algoritmo per ogni $\epsilon > 0$ tale che $A_\epsilon$ è un $()1+\epsilon$-approximation algorithm (per problemi di minimizzazione) o un $(1-\epsilon)$-approximation algorithm (per problemi di massimizzazione).\\
Oltre a queste due definizioni riportate in \cite{williamson2011design}, è interessante fornire le definizioni tratte dal paper di riferimento di questo lavoro di tesi \cite{jerrum1993polynomial}:\\
dati numeri reali non negativi $a, \tilde{a}, \epsilon$, si dice che $\tilde{a}$ approssima $a$ in un range $(1+\epsilon)$ se
\begin{equation}
	a(1+\epsilon)^{-1} \leq \tilde{a} \leq a(1+\epsilon).
\end{equation}
Sia \textit{f} una qualsiasi funzione che mappa istanze del problema in numeri reali. Un \textit{\textbf{randomised approximation scheme}} per $f$ è un algoritmo probabilistico che, quando presentato con un'istanza $x$ ed un numero reale $\epsilon \in (0,1]$, restituisce un numero che, con alta probabilità, approssima $f(x)$ in un range $(1+\epsilon)$. Il risultato di tale algoritmo, però, non deve essere ottenuto solo con \textit{alta affidabilità}, ma anche \textit{\textbf{efficientemente}}. In accordo a ciò, si definisce un approximation scheme \textit{\textbf{fully polynomial}} se il suo tempo di esecuzione è polinomiale in $\epsilon^{-1}$ e nella taglia dell'istanza $x$ del problema.