Un \textit{sistema complesso} può essere visto come un sistema il cui comportamento complessivo risulta dall’interazione delle singole parti, ognuna con i propri obiettivi, spesso soggette ad influenze esterne. Esempi di tali sistemi si possono trovare in vari ambiti di ricerca: a partire dall’\textit{economia}, con lo studio dei mercati, dalla \textit{fisica}, con i sistemi di spin, passando per la \textit{biologia} e lo studio dell’evoluzione, fino ad arrivare all’\textit{informatica}, con lo studio di Internet e delle reti sociali. Questi sistemi sono stati studiati sempre in maniera indipendente, ma negli ultimi anni è stata messa in evidenza l’analogia tra i fenomeni che accadono al loro interno: pertanto è nato il bisogno di trovare uno strumento che fornisca un linguaggio universale comprensibile sia per le scienze naturali che sociali e che permetta di analizzare, quindi, sia la natura che la società.\\
Nel corso degli anni, la scienza ha sviluppato ben due linguaggi comuni, che si fondono per descrivere tali fenomeni: la \textit{teoria dei grafi} e la \textit{teoria dei giochi}. La teoria dei grafi \cite{easley2010networks} è una branca della matematica, nata nel 1700, che consente di descrivere le relazioni che intercorrono tra un insieme di oggetti. Il grafo è lo strumento attraverso il quale tali relazioni possono essere espresse ed organizzate. Esso consiste di oggetti chiamati \textit{nodi} e relazioni tra coppie di questi oggetti detti \textit{archi}; tale struttura gode di notevole versatilità: questa caratteristica, in unione alla completa pervasività della tecnologia in ogni ambito operativo umano, fa sì che sia possibile rilevare il grafo nei contesti più variegati, così da essere in grado di analizzare i comportamenti dei suoi nodi. Per modellare il comportamento dei singoli componenti viene utilizzata la \textit{teoria dei giochi}, un campo che riesce ad abbracciare i sistemi complessi nei vari ambiti: economico, biologico, fisico, informatico, sociologico e così via.\\
La \textit{teoria dei giochi} \cite{easley2010networks}, tratta con un insieme di \textit{giocatori}, ognuno dei quali possiede un insieme di possibili azioni che può intraprendere, dette anche \textit{strategie}. Ciascun agente sceglie la propria strategia in accordo ad una funzione, detta \textit{payoff}, che non dipende solo dalla strategia del giocatore stesso, ma anche dalle strategie scelte da tutti gli altri giocatori. Il modo in cui tali giocatori modificano le loro strategie in accordo alle scelte effettuate dagli altri, definisce la dinamica del gioco e descrive, quindi, come tale gioco evolve. Se la dinamica, dopo un certo periodo di tempo, raggiunge un punto fisso (cioè uno stato di stabilità), si dice che il gioco è in \textit{equilibrio}.\\
La \textit{teoria dei giochi} classica assume che ogni giocatore abbia una \textit{conoscenza completa} del gioco (conosce tutti gli altri giocatori, i loro insiemi di strategie e i loro \textit{payoff} e, in più sa che anche gli altri giocatori hanno le stesse informazioni); assume, inoltre, che ogni agente abbia una potere computazionale illimitato e, pertanto, riesca sempre a scegliere la strategia che massimizza la sua utilità. In questo modello \textit{razionale}, l’evoluzione di un sistema viene modellata attraverso la \textit{best response dynamic}, ed è possibile fare predizioni sul gioco utilizzando il ben noto \textit{equilibrio Nash}. Tuttavia, in molti casi concreti l’assunzione fatta dalla \textit{game theory} classica, può essere irrealistica: i sistemi complessi sono spesso influenzati da fattori ambientali che possono, a loro volta, influire sul modo con cui un giocatore sceglie la propria strategia; inoltre, i giocatori possono avere capacità computazionali limitate, e ciò rappresenta il principale limite soprattutto in sistemi informatici e sociali, e conoscenze limitate circa i fattori esterni che possono influenzare il gioco.\\
Pertanto, c’è bisogno di definire dinamiche che siano capaci di modellare la \textit{bounded rationality} (conoscenza limitata), in cui i giocatori possano prendere decisioni sbagliate, e che portino auspicabilmente il sistema a raggiungere un \textit{equilibrio} che esista sempre, sia unico e velocemente raggiungibile. La \textit{Logit dynamics}, introdotta da Blume \cite{blume1993statistical}, modella le dinamiche di questo tipo. In una \textit{Logit dynamics}, descritta in dettaglio nel Capitolo \ref{chap3}, ad ogni passo si sceglie a caso un giocatore per permettergli di modificare la propria strategia in accordo ad un parametro $\beta$ che rappresenta il livello di razionalità (o conoscenza) e allo stato del sistema (le strategie attualmente scelte dagli altri giocatori). Tale modo di operare avviene nel rispetto di una regola detta \textit{logit update rule}, che può essere vista come la versione ``rumorosa'' della classica \textit{best response rule}, dove $\beta$ rappresenta la tendenza verso le scelte che sono buone. Intuitivamente, valori piccoli di $\beta$ rappresentano situazioni in cui i giocatori sono soggetti a forte rumore, oppure hanno una conoscenza molto limitata del gioco e, di conseguenza, scelgono le loro strategie in maniera quasi casuale; grandi valori di $\beta$, invece, rappresentano situazioni in cui i giocatori sono quasi sicuri di giocare la loro \textit{best response}. Questo modello è molto simile ad un altro modello utilizzato dai fisici per descrivere i \textit{sistemi di particelle}, dove il comportamento di ogni singola particella è influenzato dalla temperatura: qui, alta temperatura significa bassa razionalità e bassa temperatura, invece, indica alta razionalità.\\
Come affermato in \cite{blume1993statistical}, è ben noto che tale dinamica definisce una \textit{catena di Markov} sull’insieme di profili di strategie del gioco e, inoltre, è noto che esiste sempre un’unica \textit{distribuzione stazionaria} verso cui la catena converge, indipendentemente dal profilo di partenza. È facile vedere che la catena di Markov in questione è \textit{ergodica}, pertanto esiste un’unica distribuzione stazionaria $\pi$ e, per ogni stato iniziale $x$, la distribuzione della catena al tempo $t$ approccia a $\pi$ man mano che $t$ tende ad infinito (maggiori dettagli in \ref{ssec:stazdist} e in \ref{ergmc}).\\
Consideriamo ora un \textit{potential game}. Un gioco $G = ([n], S, \mathcal{U})$ è detto \textit{potential game} se esiste una funzione $\Phi : S_n \times \cdots \times S_n \rightarrow \mathcal{R}$ tale che per ogni giocatore \textit{i} e per ogni coppia di profili $x$ ed $y$ che differiscono solo per la posizione \textit{i}, si ha che $u_i(x) - u_i(y) = \Phi(x) - \Phi(y)$.\\
In \cite{blume1993statistical} è possibile vedere che se $\mathcal{G}$ è un \textit{potential game} con funzione potenziale $\Phi$, allora la catena di Markov descritta in precedenza è reversibile e la sua distribuzione stazionaria è data dalla \textit{Gibbs measure}. In più, quando $\mathcal{G}$ è un potential game, la \textit{Logit dynamics} è equivalente alla ben nota Glauber dynamics \cite{martinelli1999lectures}; ciò significa che la \textit{Logit dynamics} per $\mathcal{G}$ e la Glauber dynamics per la Gibbs distribution definiscono la stessa catena di Markov.\\ Grazie a tale analogia, ci si può riferire alla terminologia utilizzata dai fisici per indicare le quantità coinvolte; in particolare il parametro $\beta$ è detto \textit{inverse temperature} ed il fattore di normalizzazione presente nella distribuzione stazionaria (che sarà indicato con Z) è detto \textbf{\textit{partition function}}. Maggiori dettagli in \ref{ssec:logitglauber}.\\

\textbf{Obiettivo del lavoro}. L’obiettivo di questo lavoro di tesi è quello di proporre un algoritmo, applicabile in contesti del mondo reale, per la computazione della distribuzione stazionaria della catena di Markov relativa alla \textit{Glauber dynamics} nel modello di Ising.\\ La pubblicazione che ha dato il via a questa linea di ricerca è stata quella di Jerrum e Sinclair in \cite{jerrum1993polynomial} nel 1993, che ha spostato il problema nell'ambito del \textit{subgraphs-world}, fornendo un algoritmo polinomiale, ma non abbastanza scalabile da poter essere utilizzato in pratica. Per questo è stata necessaria un'attenta analisi del lavoro di Jerrum e Sinclair, così da poterne migliorare i bound temporali, rendendo l'esecuzione molto più efficiente, anche grazie al contributo apportato da Auletta, Ferraioli, Pasquale, Penna, Persiano in \cite{auletta2011convergence}, integrato in questo lavoro. Quindi sono stati affinati i teoremi, i lemmi e le assunzioni, i concetti assimilati, ottimizzati ed inglobati all'interno dell'algoritmo sviluppato.\\
Il lavoro svolto ha portato a raggiungere notevoli risultati. Infatti, l'algoritmo proposto, oltre al portare a termine l'esecuzione di esperimenti su reti di piccole-medie dimensioni in secondi, consente di computare la \textit{partition function} anche su reti di medie-grandi dimensioni in tempi ragionevoli, cosa prima assolutamente fuori portata, basti considerare che il tempo d'esecuzione per uno stesso esperimento è stato abbattuto da ore a secondi.\\
Inoltre è stata verificata la bontà dell'algoritmo sviluppato con un'applicazione pratica nota come ``\textit{The Effectiveness of Advertising}'' su grafi di medie dimensioni, in cui si va calcolare la magnetizzazione della rete a partire dalla sua struttura e dalla polarizzazione dei singoli nodi. In termini economici, questo si traduce nel poter prevedere il risultato della pubblicizzazione di due prodotti, ottenendo la preferenza finale della popolazione.\\

\textbf{Related works}. I primi lavori riguardanti la \textit{Logit dynamics} hanno focalizzato la loro attenzione principalmente sul comportamento a lungo termine delle dinamiche considerate: Blume \cite{blume1993statistical} ha mostrato che, per \textit{coordination games} $2 \times 2$ e per \textit{potential games} il comportamento a lungo termine del sistema è concentrato in uno specifico equilibrio Nash; Al{\'o}s-Ferrer e Netzer \cite{alos2010logit} danno una caratterizzazione generale del comportamento a lungo termine di tali dinamiche per un’ampia gamma di classi di giochi.\\
Un numero considerevole di lavori si è dedicato ad analizzare il tempo che la dinamica impiega per raggiungere un equilibrio Nash, chiamato \textit{hitting time}: tra questi è rilevante considerare il lavoro di Peyton Young \cite{young2006diffusion} che ha esteso tali considerazioni per famiglie più generali di grafi.\\
Ci sono stati, inoltre, lavori che si sono focalizzati sulla descrizione di un ulteriore equilibrio nella \textit{game theory} relativamente alle \textit{Logit dynamics}: Ferraioli in \cite{ferraioli2012logit} descrive un nuovo equilibrio chiamato \textit{Logit equilibrium} e introduce un nuovo concetto chiamato \textit{metastability}; Auletta, Ferraioli, Pasquale, Penna, Persiano in \cite{auletta2011convergence} descrivono la convergenza verso tale equilibrio della \textit{Logit dynamics} per un \textit{potential game}, mentre in \cite{auletta2012metastability}, Auletta, Ferraioli, Pasquale, Persiano descrivono la convergenza verso la \textit{metastability} di \textit{coordination games}.\\
Il lavoro più recente \cite{rinaldi2016approximation} raggiunge l'obiettivo di computare la funzione di partizione Z in tempo polinomiale: l'intuizione è quella di far girare un'altra dinamica che goda di due importanti proprietà, ovvero la convergenza ``rapida'' alla distribuzione stazionaria ed il poter utilizzare tale stazionaria per calcolare quella di nostro interesse. La nuova dinamica in questione è quella proposta in \cite{jerrum1993polynomial} da Mark Jerrum ed Alistair Sinclair nel lavoro ``Polynomial time approximation algorithms for the Ising model'', in cui presentano un algoritmo di approssimazione per il calcolo della partition function Z per il modello di Ising, un classico problema combinatoriale della fisica statistica; l’algoritmo proposto è un \textit{fully polinomial randomised approimation scheme} (fpras) ed ha tempo d’esecuzione polinomiale. Tale articolo rappresenta il punto di partenza su cui si basa \cite{rinaldi2016approximation}, ma nonostante l'approfondita analisi e le ottimizzazioni che introduce, non si raggiunge una concretezza pratica che renda in grado di utilizzare tale algoritmo in situazioni reali.\\

\textbf{Organizzazione della tesi.}
Nel Capitolo \ref{chap1} saranno introdotti alcuni concetti base utili a comprendere il lavoro proposto in questa tesi. In particolare si descrivono alcuni concetti di teoria dei grafi, passando poi alla definizione del modello di Ising, focus di tutto il lavoro; si prosegue con cenni sulle probabilità e sulle catene di Markov, terminando con la definizione di algoritmo di approssimazione. Nel Capitolo \ref{chap3} si descrive la \textit{Logit dynamics}, focalizzando l’attenzione su alcune proprietà e sulle motivazioni che hanno portato all’adozione di tale dinamica per modellare i sistemi complessi. Nel Capitolo \ref{chap4}, si descrive l’algoritmo proposto in \cite{jerrum1993polynomial}, che ha gettato le basi per questo lavoro di tesi. Successivamente, nel Capitolo \ref{chap5} si descrive il contributo fornito al calcolo della \textit{\textbf{partition function}} mentre nel Capitolo \ref{chap6} si propone un nuovo metodo per calcolare il \textit{mean magnetic moment} del sistema, analizzando i miglioramenti e le ottimizzazioni proposte. Tale analisi troverà poi giustificazione nel Capitolo \ref{chap7}, in cui verranno mostrati principalmente i risultati ottenuti effettuando dei test sugli algoritmi descritti nei capitoli precedenti, mostrandone i risultati e confrontando questi ultimi con quelli ottenuti in \cite{rinaldi2016approximation}. Nel capitolo \ref{chap7}, inoltre, è mostrato un esempio di applicazione dell’algoritmo proposto per il calcolo del numero atteso di nodi di un grafo che utilizzano un dato prodotto, simulando una campagna pubblicitaria su tale network. Si conclude infine, nel Capitolo \ref{chap8}, con alcune considerazioni e proposte di sviluppi futuri.